# log_metrics 输出指南

本文档说明 `analyzer/log_metrics` 产生什么输出，以及这些输出应如何正确解读。

## 1. 用途与范围

`analyzer/log_metrics` 模块处理的是 **Conflux 节点运行时指标** — 每个 Conflux 节点在运行过程中定期写入 `metrics.log` 的键值对统计数据。这些指标涵盖计数器（如已处理的区块数）、仪表盘值（如队列深度）和时间度量，均由 Conflux-Rust 客户端中的插桩模块发出。

该模块有两条输出路径。主路径是 `__main__.py` 与 `parse_metrics.py` 产生的图表输出；次路径是 `analysis.py` 与 `parse_metrics.py` 辅助函数产生的文本对比表。

---

## 2. 核心概念

本节定义后续章节中引用的术语和机制。

### 2.1 指标命名：`module::key`

每个指标由 **module**（发出该指标的 Conflux 子系统，匹配 `[0-9a-z_]+`）和 **key**（该模块内的具体度量）两部分组成。完整形式为 `module::key`。裸 `key` 仅在该 key 在所有模块中唯一时可用；若跨模块重名则触发歧义异常。为保证脚本稳定性与可复现性，建议始终使用 `module::key`。

### 2.2 双层百分位节点选择

测试网络可能包含数百个节点，若绘制每个节点的时序曲线将难以阅读。本模块采用**双层百分位**策略来选择有代表性的节点。

第一层（节点内部）：对每个节点计算一个标量代表值，默认取该节点该指标的第 90 百分位（`node_percentile=90`）。

第二层（跨节点）：按代表值在全网节点中排序，并在指定的全局百分位位置（`plot_percentiles`，默认 `[0, 10, 50, 90, 100]`）各取一个节点。

因此图例中 `P0` 表示"代表值在所有节点中最低的节点"，`P50` 表示"中位节点"，`P100` 表示"代表值最高的节点"。这些标签标识的是**被绘制的节点是哪个**，而非每个时刻的全网分位线。

### 2.3 派生 `.m1` 指标

在绘图和统计之前，预处理会为所有以 `.count` 结尾的指标生成 `<original>.m1`。`.m1` 的值是计数增量的时间衰减加权平均，本质上是一个平滑的短期速率/吞吐信号，与原始累计计数 `.count` 相对应。

计算过程分三步。

1. 构建增量序列：`diff[i] = value[i] - value[i-1]`（首点保持原值）。
2. 按相邻采样点的时间间距（分钟尺度）构建指数衰减权重。
3. 输出每个时间戳对应的加权结果。

---

## 3. CLI 的实际输出

主入口命令是 `python -m analyzer.log_metrics -l <log_dir> -o <output_dir> -m <metric1> <metric2> ...`。

对于 `-m` 中的每个指标，程序先执行 `GlobalMetricsStats.preprocessing` 预处理并在各节点目录写入 `metrics.pq` 缓存，再根据双层百分位策略（第 2.2 节）选择代表节点，绘制时序图，并保存 PDF 文件。

### 文件输出

缓存文件路径是 `<log_dir>/<node_ip>/metrics.pq`。图表文件路径是 `<output_dir>/<sanitized_metric_name>.pdf`。

### 终端输出

终端通常会出现多进程 `tqdm` 进度条，以及绘图前打印的 `paths_and_tags`。如果覆盖率不足，会输出警告：`警告: 在 <log_dir> 中仅找到 <valid>/<total> 个节点具有指标 <metric_name>`。触发条件是具有该指标的节点比例低于 80%。

---

## 4. 输入日志解析规则

解析器只处理符合 `<timestamp>, <module>, Group, {k1: v1, k2: v2, ...}` 结构的日志行。

约束较严格。`timestamp` 按整数毫秒处理，`module` 必须匹配 `[0-9a-z_]+`（第 2.1 节），指标值必须可解析为浮点数。不匹配的行会被静默跳过。因此输出的完整性和准确性直接依赖 `metrics.log` 是否满足该格式。


---

## 5. 图表语义

图的 X 轴是墙上时钟时间（`HH:MM`），Y 轴是指标值且下界固定为 0。每条曲线对应一个被选中的代表节点（来自第二层百分位选择，第 2.2 节），`extra_nodes` 参数可额外增加曲线。

单位处理由参数决定。默认保持日志原始单位；若 `nano_seconds=True`，数值会除以 `1e9` 并按秒（`s`）展示。时间过滤通过 `time_range="HH:MM-HH:MM"` 完成，采用本地时间并支持跨午夜区间。

---

## 6. 文本对比表输出

`analysis.py` 提供两个日志目录之间的比较输出。

### `compare_logs(...)`

表头是 `指标`、`倍数`、`基准值`、`对比值`，其中 `倍数 = compare / base`。其处理流程是：先在两个 run 中各选一个全局百分位节点（默认 `global_p=90`），再跳过缺失或为 0 的指标，最后按倍数降序输出，并先打印被跳过的指标名。

### PrettyTable 辅助输出

`parse_metrics.py` 中还有 `print_node_stats_table` 与 `print_global_stats_table` 两个格式化函数，用于打印节点级与全局级分位统计，但它们不会被 `__main__.py` 自动调用。

---

## 7. 解读核对清单

阅读单个 PDF 时，建议按顺序检查以下问题。

1. 当前指标是原始 key 还是派生 `.m1` 速率指标（第 2.3 节）？
2. Y 轴单位是原始值还是纳秒转秒？
3. 图例 `P0/P50/P100` 是否按"节点排序桶"理解，而非每个时刻的全网分位线（第 2.2 节）？
4. `valid/total` 覆盖率警告是否可接受？
5. 若结果异常，原始日志格式与模块/键命名是否满足解析规则（第 2.1 节、第 4 节）？
